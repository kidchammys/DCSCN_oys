{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f7eace6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Count of using GPUs: 0\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13860/24318515.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13860/24318515.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Device:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 출력결과: cuda\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Count of using GPUs:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 출력결과: 2 (2, 3 두개 사용하므로)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Current cuda device:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 출력결과: 2 (2, 3 중 앞의 GPU #2 의미)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m# Configure Data Augmentation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\2dys\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36mcurrent_device\u001b[1;34m()\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcurrent_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m     \u001b[1;34mr\"\"\"Returns the index of a currently selected device.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 479\u001b[1;33m     \u001b[0m_lazy_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    480\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_getDevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\2dys\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    206\u001b[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001b[0;32m    207\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_cuda_getDeviceCount'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             raise AssertionError(\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "from data_processing import multiprocessing_aug\n",
    "from func import utils\n",
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from DCSCN import DCSCN\n",
    "import numpy as np\n",
    "import imageio\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "def main():\n",
    "    # Checking GPU Available\n",
    "\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    print('Device:', device)  # 출력결과: cuda\n",
    "    print('Count of using GPUs:', torch.cuda.device_count())  # 출력결과: 2 (2, 3 두개 사용하므로)\n",
    "    print('Current cuda device:', torch.cuda.current_device())  # 출력결과: 2 (2, 3 중 앞의 GPU #2 의미)\n",
    "\n",
    "    # Configure Data Augmentation\n",
    "\n",
    "    DATA_DIR = ['data/bsd200', 'data/yang91']\n",
    "    OUTPUT_DIR = 'augmented_data/train_org/'\n",
    "    expected_totalaug = multiprocessing_aug(DATA_DIR,OUTPUT_DIR)\n",
    "\n",
    "    # Split Parameters\n",
    "\n",
    "    BICUBIC_DIR = 'augmented_data/train_sr/LRBICUBIC'\n",
    "    LRX2_DIR = 'augmented_data/train_sr/LRX2'\n",
    "    HR_DIR = 'augmented_data/train_sr/HR'\n",
    "\n",
    "    lr_batch_size = 32\n",
    "    scale = 2\n",
    "    train_list = utils.load_img(OUTPUT_DIR,expected_totalaug)\n",
    "    HR_LIST, LR_LIST, BI_LIST = utils.build_data(train_list, lr_batch_size, scale, BICUBIC_DIR, LRX2_DIR, HR_DIR)\n",
    "\n",
    "    # TORCH BATCH DATASET\n",
    "    batch_size = 20\n",
    "    train_dataset = torch.utils.data.TensorDataset(LR_LIST, HR_LIST, BI_LIST)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=True\n",
    "    )\n",
    "\n",
    "    if len(HR_LIST) == len(LR_LIST) == len(BI_LIST):\n",
    "        total_batch_num = len(data_loader)\n",
    "        pass\n",
    "    else:\n",
    "        print(\"ERROR : NOT MATCH NUMBER OF PAIR BATCH DATA\")\n",
    "        exit()\n",
    "\n",
    "    MODEL = DCSCN().to(device)\n",
    "    print(MODEL)\n",
    "\n",
    "\n",
    "    lr = 1e-4\n",
    "    total_epochs = 100\n",
    "    model_path = 'save_model'\n",
    "    optimizer = optim.Adam(MODEL.parameters(),lr = lr)\n",
    "    loss_func = torch.nn.MSELoss().to(device)\n",
    "\n",
    "    for epochs in range(total_epochs):\n",
    "        avg_loss = 0.0\n",
    "        batch_num = 0\n",
    "        for LR,HR,BI in data_loader:\n",
    "            optimizer.zero_grad()\n",
    "            recon = MODEL(LR.to(device))\n",
    "            recon += BI.to(device)\n",
    "            loss = loss_func(recon, HR.to(device))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            avg_loss += loss / batch_size\n",
    "\n",
    "            if batch_num % 1000 == 0 :\n",
    "                print(\"{}/{} Training....batch_loss {}!\".format(batch_num,total_batch_num, avg_loss/batch_num))\n",
    "\n",
    "            batch_num += 1\n",
    "\n",
    "\n",
    "        avg_loss = avg_loss / total_batch_num\n",
    "        print(\"Epoch {}/{} loss {}\".format(epochs, total_epochs, avg_loss))\n",
    "        if epochs % 10 == 0:\n",
    "            save_model_path = model_path + \"/DCSCN_V2_e{}_lr{}_loss{:4}.pt\".format(epochs,lr,loss)\n",
    "            torch.save(MODEL, save_model_path)\n",
    "\n",
    "            print(\"SAVE MODEL EPOCH {}\".format(epochs))\n",
    "\n",
    "\n",
    "    # Last save\n",
    "\n",
    "    save_model_path = model_path + \"/DCSCN_V2_e{}_lr{}.pt\".format(epochs, lr)\n",
    "    torch.save(MODEL, save_model_path)\n",
    "\n",
    "    print(\"LAST SAVE MODEL EPOCH {}\".format(epochs))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
